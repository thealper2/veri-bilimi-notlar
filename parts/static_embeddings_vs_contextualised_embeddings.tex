\section{Static Embeddings ve Contextualised Embeddings}
Static (Context-unaware) Embedding, her kelimenin bir vektör temsilini sabit bir şekilde atar. Her kelimenin temsili, kelimenin metin içindeki kullanımıyla ilgili hiçbir bilgiyi dikkate almaz yani kelimenin çevresel bağlamını göz önünde bulundurmaz. Statik embedding modelleri, büyük metin verilerini kullanarak kelime vektörlerini önceden eğitir. Örneğin Word2Vec ve GloVe.

Kontekstüal (Context-aware) Embedding, her kelimenin temsili için çevresel bağlamı dikkate alır. Her kelimenin temsili, o kelimenin metin içindeki kullanımıyla bağlantılıdır ve bu kullanımı dikkate alarak dinamik olarak değişir. Özellikle, her kelimeye, o kelimenin metindeki konumu ve etkileşimde olduğu diğer kelimeler gibi çevresel bilgileri dikkate alan bir temsil atanır. Bu işlem için genellikle dikkat (attention) mekanizmaları kullanılır. Örneğin BERT, GPT, RoBERTa.

\newpage