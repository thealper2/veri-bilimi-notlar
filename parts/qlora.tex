\section{Q-LoRA (Quantized Low-Rank Adaptation)}

Q-LoRA, LoRA'yı kuantizasyon teknikleri ile birleştirir. Kuantizasyon, modelin ağırlıklarının daha düşük bit genişliklerinde (4-bit, 8-bit) temsil edilmesini sağlar. Böylece bellek kullanımını ve hesaplama maliyetini azaltır. Kuantize edilmiş modelin belirli katmanlarına düşük dereceli matrisler eklenir. Kuantizasyon, model performansını biraz düşürebilir çünkü düşük bit genişlikleri ağırlıkların doğruluğunu azaltır.


\newpage