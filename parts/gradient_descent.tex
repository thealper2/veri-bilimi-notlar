\section{Gradient Descent}
\subsection{Batch Gradient Descent}
Tüm eğitim örneklerini bir arada kullanarak her bir iterasyonda gradyanı hesaplayar ve parametreleri günceller. Veri setinin tamamını kullanarak güncellemeler yapmak daha kararlı ve doğru sonuçlar elde etmeyi sağlar fakat büyük veri setleri için hesaplama maliyeti yüksek olabilir. Tüm veri seti kullanılarak tek bir gradyan hesaplanır. Parametreler, tüm veri setinin gradyanı hesaplandıktan sonra bir kez güncellenir.

\[\theta = \theta - \alpha \nabla J(\theta)\]
\begin{itemize}
	\item $\theta$: optimize edilen parametrelerin vektörü,
	\item $\alpha$: öğrenme oranı,
	\item $J(\theta)$: maliyet fonksiyonunun gradyanı.
\end{itemize}

\subsection{Stochastic Gradient Descent (SGD)}
Her bir eğitim örneği için ayrı ayrı gradyan hesaplayarak parametreleri günceller. Diğer gradyan inişi türevlerine göre daha hızlı güncellemeler sağlar ancak her bir güncelleme daha rastgele olduğu için dalgalanmalara sebep olabilir. Her bir eğitim örneği için ayrı ayrı gradyanlar hesaplanır. Her bir eğitim örneği için gradyan hesaplandığı için güncelleme sıklığı çok yüksektir.

\[\theta = \theta - \alpha \nabla J(\theta; x^{i}, y^{i} )\]
\begin{itemize}
	\item $\theta$: optimize edilen parametrelerin vektörü,
	\item $\alpha$: öğrenme oranı,
	\item $J(\theta; x^{i}, y^{i} )$: maliyet fonksiyonu,
	\item $x^{i}$ ve $y^{i}$: eğitim veri setindeki i'inci örnek.
\end{itemize}

\subsection{Mini Batch Gradient Descent}
Her bir iterasyonda tüm veri setini değil, belirli bir alt küme (mini batch) üzerinde işlem yapar. Bu, batch gradient descent'in hesaplama maliyetini azaltır ve stochastic gradient descent'in rastgele dalgalanmaları azaltmasını sağlar. Mini batch içerisindeki örnekler için gradyanlar hesaplanır. Belirli bir mini batch üzerinde gradyan hesaplandığı için güncelleme sıklığı batch gradient descent'e göre daha sık, stochastic gradient descent'e göre daha düzenlidir.

\[\theta = \theta - \alpha \cdot \frac{1}{|\text{mini batch}|} \sum_{i=1}^{|\text{mini batch}|} \nabla J(\theta;x^{(i)},y^{(i)})\]
\begin{itemize}
	\item $\theta$: optimize edilen parametrelerin vektörü,
	\item $\alpha$: öğrenme oranı,
	\item ${|\text{mini batch}|}$: mini batch'deki örneklerin sayısı,
	\item $J(\theta;x^{(i)},y^{(i)})$: maliyet fonksiyonu,
	\item $x^{i}$ ve $y^{i}$: eğitim veri setindeki i'inci örnek.
\end{itemize}

\newpage