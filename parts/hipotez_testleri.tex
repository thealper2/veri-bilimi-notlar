\section{Hipotez Testleri}
Hipotez testleri, verilerin istatistiksel olarak anlamlı sonuçlar üreterek, belirli hipotezlerin geçerliliğini veya kabul edilip edilmemesi gerektiğini değerlendirmemize yardımcı olur.

\begin{enumerate}
    \item Model Performansı Testleri: Makine öğrenmesi modellerinin performansını değerlendirmek için hipotez testleri kullanılır.
    \item Özellik Seçimi: Modelin performansını artırabilecek özelliklerin tespitinde hipotez testleri kullanılır. Gereksiz veya zararlı özellikleri eleme, önemli özellikleri belirlemeye yardımcı olur.
    \item A/B Testleri: A/B testleri, bir değişikliğin (yeni bir model vb.) mevcut bir sisteme etkisini değerlendirmek için kullanılır. İki grup arasındaki farkın anlamlı olup olmadığını belirlemek için kullanılır hipotez testleri yapılır.
\end{enumerate}
Hipotez testlerinin genel işlevleri;
\begin{enumerate}
    \item Null (H0) ve alternatif (H1) hipotezler belirleme: Null hipotezi mevcut bir durumu veya varsayımı ifade ederken, alternatif hipotez, bir değişiklik veya farkı ifade eder. Hipotez testleri, bu iki hipotezi karşılaştırarak bir sonuç çıkarır.
    \item Veriye dayalı kararlar alma
    \item Anlamlılığı değerlendirme
\end{enumerate}

\subsection{Homojen Varyanslılık (Homoscedasticity)}
Homojen varyanslılık, bir dizi değişkenin varyanslarının eşit olduğu varsayımıdır. Varyansın sabit olduğu anlamına gelir ve ANOVA, regresyon analizlerinde bu varsayımın geçerli olması önemlidir. 

\subsection{Post hoc Testleri}
ANOVA testleri, birden fazla grubun ortalamalarını karşılaştırmak için kullanılır ve gruplar arasında en az birinin farklı olup olmadığını belirler. Ancak, hangi grupların birbirinden farklı olduğunu göstermez. Bu yüzden post hoc testleri kullanılır. Post hoc testleri, gruplar arasındaki spesifik farkları belirlemek için kullanılır.

\subsection{Hipotez Testi Türleri}
\begin{enumerate}
    \item \textbf{Z-Testi ve T-Testi:} Bir örneklem verisi ile bir örneklem ortalama arasındaki farkın anlamlı olup olmadığını belirlemek için kullanılır. Eğer popülasyon standart sapması biliniyorsa Z-testi kullanır; bilinmiyorsa ve örneklem büyüklüğü küçükse T-testi kullanır.
    \item \textbf{İki Örneklem T-testi:} İki farklı önreklem grubu arasındaki ortalama farkın istatistiksel olarak anlamlı olup olmadığını değerlendirmek için kullanılır.
    \item \textbf{Tek Yön Testi (one-tailed) ve İki Yön Testi (two-tailed):} Tek yön testi, sonuçların sadece bir yönde anlamlı olup olmadığını değerlendirir. İki yön testi, iki yönde de anlamlı olup olmadığını kontrol eder.
    \item \textbf{Ki-Kare (Chi-Square) Testi:} İki veya daha fazla kategorik değişken arasındaki bağlantıyı veya bağımsızlık ilişkisini incelemek için kullanılır. Özellikle kategori sayısı yüksek olduğunda örneklem büyüklüğü uygun olduğunda kullanışlıdır.
    \item \textbf{ANOVA (Varyans Analizi):} Üç veya daha fazla grup arasındaki ortalama farklılıkları değerledirmek için kullanılır. Grupların varyanslarının birbirine göre istatistiksel olarak anlamlı farklılık gösterip göstermediğini kontrol eder.
    \item \textbf{Mann-Whitney U Testi:} İki grup arasındaki medyan değerlerinin farklı olup olmadığını değerlendirmek için kullanılır. Verilerin normal dağılmadığı veya eşit varyansa sahip olmadığı durumlarda kullanılabilir.
    \item \textbf{Wilcoxon İşaretli Sıralar Testi:} İki bağımlı grup arasındaki farklılığı değerlendirmek için kullanılır. İki grup arasındaki medyan farklılığına odaklanır.
    \item \textbf{Pearson Korelasyon Katsayısı Testi:} İki sürekli değişken arasındaki ilişkiyi ölçer. Korelasyon katsayısı, değişkenler arasındaki ilişkinin yönünü ve gücünü belirler.
\end{enumerate}

\newpage

\subsection{A/B Testi}
A/B Testi, iki veya daha fazla farklı sürümün karşılaştırılması amacıyla kullanılan bir istatistiksel deney tasarımıdır. A/B Testi, işletmelerin, web sitelerinin, uygulamaların veya pazarlama stratejilerinin etkisini değerlendirmek ve karşılaştırmak için yaygın olarak kullanılır. A/B test, hangi sürümün daha etkili veya kullanıcılar için daha çekici olduğunu belirlemek için kullanılır.\\
A/B Testi işlevleri:
\begin{itemize}
    \item Farklı sürümleri karşılaştırma
    \item İstatistiksel anlamda karar verme: A/B testi, her iki sürüm arasındaki farkın rastgele varyasyondan kaynaklanıp kaynaklanmadığını belirlemek için istatistiksel yöntemler kullanır.
\end{itemize}

Terimler
\begin{itemize}
    \item \textbf{Kontrol Grubu (Grup A):} Mevcut sürüm veya mevcut uygulama olan kontrol grubu olarak adlandırılır.
    \item \textbf{Deneme Grubu (Grup B):} Yeni bir sürüm veya değişiklik içeren deneme grubu olarak adlandırılır.
    \item \textbf{Metrik:} Değerlendirilmek istenen anahtar performans göstergesi (KPI). Örneğin tıklanma oranı, dönüşüm oranı, gelir vb.
    \item \textbf{Hipotezler:} Testin temelini oluşturan hipotezler belirlenir. Genellikle null hipotez (H0) ile alternatif hipotez (H1) olarak iki hipotez kullanılır. Sıfır hipotezi (null hipotez - H0), test edilen iki grubun arasındaki farkın önemli olmadığını savunur. Örneğin, A sınıfı ve B sınıfı adında iki sınıf olduğunu, bu sınıflardaki öğrencilerin not ortalamalarının farklı olup olmadığını test etmek istediğimizi varsayalım. Bu durumda sıfır hipotezi "A sınıfının ve B sınıfının not ortalamalarının arasında bir fark yoktur." olur. Alternatif hipotez (H1) ise sıfır hipotezinin tersidir. Yani bu durumda alternatif hipotez, "A sınıfının ve B sınıfının not ortalamalarının arasında fark vardır." olur.
\end{itemize}

Örnek Kullanım Senaryoları
\begin{itemize}
    \item İşletmenizde veya projenizde farklı sürümler veya değişiklikler yapmak istediğinizde.
    \item Hangi sürümün veya değişikliğin daha iyi sonuçlar getireceğini anlamak istediğinizde.
    \item Kullanıcı deneyimini veya iş sonuçlarını iyileştirmek için veriye dayalı kararlar almak istediğinizde.
\end{itemize}

Bu örnek, iki grup arasındaki ortalama farkı t-testi kullanarak test eder ve sonucu istatistiksel olarak değerlendirir. Eğer p değeri 0.05'ten küçükse, deneme grubunun kontrol grubundan istatistiksel olarak anlamlı bir şekilde farklı olduğu sonucuna varılır. P değeri (p-value), bir hipotez testinin sonucunun istatistiksel anlamlılığını ölçen bir metriktir. P değeri, test edilen hipotezin geçerliliği hakkında bilgi verir. P değeri şu şekilde yorumlanır:
\begin{itemize}
    \item P değeri küçükse (örneğin, $p < 0.05$), bu, null hipotezin (H0) reddedildiği ve verilerinizin alternatif hipoteze (H1) daha yakın olduğu anlamına gelir. Yani, p değeri düşük olduğunda, sonuçlar genellikle anlamlıdır ve test edilen değişkenler arasında bir fark olduğu gösterilir.
    \item P değeri büyükse (örneğin, $p > 0.05$), bu, null hipotezin reddedilmediği ve verilerinizin alternatif hipoteze daha uzak olduğu anlamına gelir. Yani, p değeri yüksek olduğunda, sonuçlar genellikle anlamlı değildir ve test edilen değişkenler arasında bir fark olmadığı gösterilir.
\end{itemize}

Yani, p değeri küçüldükçe, sonuçlar daha anlamlı hale gelir. Bu nedenle, p değerinin küçük olması, genellikle hipotez testlerinde tercih edilen bir durumdur, çünkü bu, verilerin test edilen değişkenler arasında bir ilişki olduğunu gösterdiği anlamına gelir.

\subsubsection{Python Kodu}

\begin{lstlisting}[language=Python]
import numpy as np
import scipy.stats as stats

control_group = [0, 1, 1, 1, 0, 1, 0, 0, 1, 0]
treatment_group = [1, 1, 1, 1, 1, 0, 1, 0, 1, 0]

control_mean = np.mean(control_group)
treatment_mean = np.mean(treatment_group)

# T-testi
t_stat, p_value = stats.ttest_ind(control_group, treatment_group)

if p_value < 0.05:
    print("Deneme grubu istatistiksel olarak anlamli bir fark yaratti.")
else:
    print("Deneme grubu istatistiksel olarak anlamli bir fark yaratmadi.")

# Output
# Deneme grubu istatistiksel olarak anlamli bir fark yaratmadi.
\end{lstlisting}

\newpage

\subsection{Z-Testi}
Z testi, bir örneklem verisinin popülasyon parametreleri hakkında istatistiksel bir hipotez testi yapmak için kullanılan bir istatistiksel testtir. Z testi, özellikle popülasyonun standart sapması bilindiğinde veya örneklem büyüklüğü büyük olduğunda kullanılır. İki türü vardır:

\begin{itemize}
    \item Tek örneklem Z testi: Bir popülasyonun ortalama değerinin belirli bir değere eşit olup olmadığını test etmek için kullanılır. Örneklem verisi ile popülasyon parametresi arasındaki farkın anlamlı olup olmadığını değerlendirmek için kullanılır.
    \item İki örneklem Z testi: ;ki farklı örneklem grubunun ortalama değerlerinin birbirine eşit olup olmadığını test etmek için kullanılır. Örneklem verileri arasındaki farkın istatistiksel olarak anlamlı olup olmadığını değerlendirir.
\end{itemize}

\subsubsection{Python Kodu}

\begin{lstlisting}[language=Python]
import numpy as np
from scipy import stats

sample_data = [25, 30, 35, 40, 45, 50]
population_mean = 45
population_stddev = 5

# Orneklem buyuklugu
n = len(sample_data)

# Z istatistigi
z_statistic = (np.mean(sample_data) - population_mean) / (population_stddev / np.sqrt(n))

# P degeri
p_value = 2 * (1 - stats.norm.cdf(abs(z_statistic)))

print("Z istatistigi:", z_statistic) # Z istatistigi: -3.674234614174767
print("P degeri:", p_value) # P degeri: 0.00023856345402872847

alpha = 0.05
if p_value < alpha:
    print("Null hipotez reddedildi: Orneklem populasyon ortalamasindan farklidir.")
else:
    print("Null hipotez kabul edildi: Orneklem populasyon ortalamasindan farkli degildir.")

# Output:
# Null hipotez reddedildi: Orneklem populasyon ortalamasindan farklidir.
\end{lstlisting}

\newpage

\subsection{T-Testi}
T testi (Student's t-test), iki grup arasındaki ortalamaların istatistiksel olarak anlamlı bir farklılık gösterip göstermediğini değerlendirmek için kullanılan bir istatistiksel test türüdür. T testi, örneklem verilerinin popülasyon parametreleri hakkında istatistiksel bir hipotez testi yapmak için kullanılır. T testi, özellikle popülasyon standart sapması bilinmediğinde veya örneklem büyüklüğü küçük olduğunda kullanışlıdır. İki türü vardır:

\begin{itemize}
    \item \textbf{Bağımsız Örneklem T-Testi:} İki farklı bağımsız örneklem grubunun ortalama değerleri arasındaki farkı test etmek için kullanılır. Örneğin, iki farklı grup arasındaki ortalama yaş farkını değerlendirmek istendiğinde bağımsız örneklem t-testi kullanılabilir.
    \item \textbf{Bağımlı Örneklem T-Testi (Eşleştirilmiş T-Test):} Aynı örneklemden alınan iki farklı örneklem grubunun ortalama değerleri arasındaki farkı test etmek için kullanılır. Örneğin, aynı kişilerin kilo kaybı ölçümleri arasındaki farkı değerlendirmek için bağımlı örneklem t-testi kullanılabilir.
\end{itemize}

\subsubsection{Python Kodu}

\begin{lstlisting}[language=Python]
import numpy as np
from scipy import stats

group1 = [25, 30, 35, 40, 45]
group2 = [30, 35, 40, 45, 50]

# Bagimsiz orneklem T-testi
t_statistic, p_value = stats.ttest_ind(group1, group2)

print("T istatistigi:", t_statistic) # T istatistigi: -1.0
print("P degeri:", p_value) # P degeri: 0.34659350708733416

alpha = 0.05
if p_value < alpha:
    print("Null hipotez reddedildi: Iki grup arasinda istatistiksel olarak anlamli bir fark vardir.")
else:
    print("Null hipotez kabul edildi: Iki grup arasinda istatistiksel olarak anlamli bir fark yoktur.")

# Output:
# Null hipotez kabul edildi: Iki grup arasinda istatistiksel olarak anlamli bir fark yoktur.
\end{lstlisting}

\subsubsection{R Kodu}

\begin{lstlisting}[language=R]
# H0: Iki grup ortalamasi birbirine esittir.
# H1: Iki grup ortalamasi esit degildir.
t.test(df$Sepal.Width ~ df$Species, mu = 0.7, var.equal = TRUE)

# H0: Iki grubun arasindaki fark 0.7'den buyuk veya esittir.
# H1: Iki grubun arasindaki fark 0.7'den kucuktur.
t.test(df$Sepal.Width ~ df$Species, mu = 0.7 , var.equal = TRUE, alternative = "less")

# H0: Iki grubun arasindaki fark 0.7'den kucuk veya esittir.
# H1: Iki grubun arasindaki fark 0.7'den buyuktur.
t.test(df$Sepal.Width ~ df$Species, mu = 0.7 , var.equal = TRUE, alternative = "greater")
\end{lstlisting}

\subsubsection{Tek Örneklem t-Testi}
Tek örneklem t testinde, örneklem ortalamasının belirli bir değerden farklılığı test edilir. Eğer ortalama eşit değilse H0 reddedilir.

\subsubsection{R Kodu}

\begin{lstlisting}[language=R]
# H0: Ortalama degeri 5'e esittir.
# H1: Ortalama degeri 5'e esit degildir.
t.test(x = iris$Sepal.Length  mu = 5, alternative = "two.sided", conf.level = 0.95)

# H0: Ortalama degeri 5'ten kucuk veya esittir.
# H1: Ortalama degeri 5'ten buyuktur.
t.test(x = iris$Sepal.Length, mu = 5, alternative = "less", conf.level = 0.95)

# H0: Ortalama degeri 5'ten buyuk veya esittir.
# H1: Ortalama degeri 5'ten kucuktur.
t.test(x = iris$Sepal.Length, mu = 5, alternative = "greater", conf.level = 0.95)
\end{lstlisting}

\newpage

\subsection{Tek Yön Testi (One-Tailed Test)}
Tek yönlü test (one-tailed test), hipotez testleri sırasında, anlamlılık düzeyini bir yönde değerlendirmenize olanak tanır. Yani, test edilen hipotez, sadece bir yönde anlamlılık aranmasına dayanır. Tek yönlü testler, hipotezinizin yönünü ve beklenen sonucu önceden belirlediğinizde kullanışlıdır. Tek yönlü testlerin iki temel türü vardır:

\begin{itemize}
    \item \textbf{Sağa Tek Yönlü Test (Right-Tailed Test):} Sağa tek yönlü testlerde, hipotez, popülasyon parametresinin belirli bir değerden büyük olduğunu test eder. Örneğin, bir yeni tedavi yöntemi ile ilgili hipotez, tedavi grubunun kontrol grubundan daha iyi olduğunu iddia ediyorsa, sağa tek yönlü bir test kullanılabilir.
    \item \textbf{Sola Tek Yönlü Test (Left-Tailed Test):} Sola tek yönlü testlerde, hipotez, popülasyon parametresinin belirli bir değerden küçük olduğunu test eder. Örneğin, bir yeni ilacın yan etkileri ile ilgili hipotez, ilacın yan etkilerinin kontrol grubundan daha düşük olduğunu iddia ediyorsa, sola tek yönlü bir test kullanılabilir.
\end{itemize}

\subsubsection{Python Kodu}

\begin{lstlisting}[language=Python]
import numpy as np
from scipy import stats

data = [25, 30, 35, 40, 45, 50]
population_mean = 40  # Hipotez: Ortalama populasyon degeri 40'tan buyuktur.

# T testi yapin (saga tek yonlu test)
t_statistic, p_value = stats.ttest_1samp(data, population_mean)

print("T istatistigi:", t_statistic) # T istatistigi: -0.6546536707079772
print("P degeri:", p_value) # P degeri: 0.5416045607931204

alpha = 0.05
if p_value < alpha:
    print("Null hipotez reddedildi: Ortalama populasyon degeri 40'tan buyuktur.")
else:
    print("Null hipotez kabul edildi: Ortalama populasyon degeri 40'tan buyuk degildir.")

# Output
# Null hipotez kabul edildi: Ortalama populasyon degeri 40'tan buyuk degildir.
\end{lstlisting}

\newpage

\subsection{İki Yön Testi (Two-Tailed Test)}
İki yönlü test (two-tailed test), hipotez testleri sırasında, anlamlılık düzeyini her iki yönde de değerlendirmenize olanak tanır. Yani, test edilen hipotez, popülasyon parametresinin belirli bir değerden farklı olduğunu test eder, ancak farkın hangi yönde olduğu önceden belirli değildir. İki yönlü testler, hipotezinizin yönünü önceden belirlemediğiniz ve iki yönde de anlamlılığı değerlendirmek istediğiniz durumlarda kullanışlıdır. İki yönlü testlerin iki temel türü vardır:

\begin{itemize}
    \item \textbf{Sağa ve Sola İki Yönlü Test (Two-Tailed Test):} İki yönlü testlerde, hipotez, popülasyon parametresinin belirli bir değerden farklı olduğunu test eder, ancak bu farkın hangi yönde olduğu önceden belirli değildir. Bu testler iki yönde anlamlılığı değerlendirirler.
    \item \textbf{Yüzde 50 Oranlı İki Yönlü Test (Two-Tailed Test):} Bu tür bir iki yönlü test, hipotezinizi yalnızca bir yönde değil, iki yönde de test etmek istediğinizde kullanılır. Örneğin, bir yeni tedavi yönteminin kontrol grubuna göre daha iyi veya daha kötü olup olmadığını değerlendirmek için kullanılabilir.
\end{itemize}

İki yönlü testler, hipotezinizin yönünü önceden belirlemediğinizde ve hangi yönde anlamlılığı değerlendirmek istediğinizde kullanışlıdır.

\subsubsection{Python Kodu}

\begin{lstlisting}[language=Python]
import numpy as np
from scipy import stats

group1 = [25, 30, 35, 40, 45]
group2 = [30, 35, 40, 45, 50]

# Iki yonlu T testi
t_statistic, p_value = stats.ttest_ind(group1, group2)

print("T istatistigi:", t_statistic) # T istatistigi: -1.0
print("P degeri:", p_value) # P degeri: 0.34659350708733416

alpha = 0.05
if p_value < alpha:
    print("Null hipotez reddedildi: Iki grup arasinda istatistiksel olarak anlamli bir fark vardir.")
else:
    print("Null hipotez kabul edildi: Iki grup arasinda istatistiksel olarak anlamli bir fark yoktur.")

# Output
# Null hipotez kabul edildi: Iki grup arasinda istatistiksel olarak anlamli bir fark yoktur.
\end{lstlisting}

\newpage

\subsection{Ki-Kare Testi (Chi-Square Test)}
Ki-kare testi (Chi-Square test), iki veya daha fazla kategorik değişken arasındaki ilişkiyi veya bağımsızlık ilişkisini değerlendirmek için kullanılan bir istatistiksel testtir. Ki-kare testi, veri seti içindeki gözlemleri ve beklenen frekansları karşılaştırarak, değişkenler arasındaki bağlantıyı veya bağımsızlığı değerlendirir. Ki-kare testi, verilerin ayrık (kategorik) olduğu durumlar için kullanışlıdır. Ki-kare testinin iki temel türü vardır:

\begin{itemize}
    \item \textbf{Ki-Kare Bağımsızlık Testi (Chi-Square Independence Test):} Bu test, iki veya daha fazla kategorik değişkenin bağımsızlık ilişkisini değerlendirir. Örneğin, bir ürünün tercih edilme durumu ile cinsiyet arasındaki ilişkiyi incelemek için bu testi kullanabilirsiniz.
    \item \textbf{Ki-Kare Uyum Testi (Chi-Square Goodness-of-Fit Test):} Bu test, bir örneklem verisinin belirli bir teorik dağılıma uyup uymadığını değerlendirir. Örneğin, bir zarın adil olup olmadığını test etmek için bu testi kullanabilirsiniz.
\end{itemize}

\subsubsection{Python Kodu}

\begin{lstlisting}[language=Python]
import numpy as np
from scipy import stats

observed_data = np.array([[30, 10], [20, 25]])
# Ki-Kare
chi2, p, _, _ = stats.chi2_contingency(observed_data)

print("Ki-kare istatistigi:", chi2) # Ki-kare istatistigi: 6.949930555555551
print("P degeri:", p) # P degeri: 0.00838224869725173

alpha = 0.05
if p < alpha:
    print("Null hipotez reddedildi: Iki degisken arasinda bagimsizlik yoktur.")
else:
    print("Null hipotez kabul edildi: Iki degisken arasinda bagimsizlik vardir.")

# Output
# Null hipotez reddedildi: Iki degisken arasinda bagimsizlik yoktur.
\end{lstlisting}

\newpage

\subsection{ANOVA (Analysis of Variance) Test}
ANOVA (Analysis of Variance), birden fazla grup arasındaki istatistiksel anlamlılığı değerlendirmek için kullanılan bir istatistiksel analiz tekniğidir. ANOVA, grupların ortalamaları arasındaki farklılıkları inceleyerek, gruplar arasında anlamlı bir fark olup olmadığını belirler. ANOVA, özellikle gruplar arasındaki varyansı karşılaştırır. ANOVA'nın iki temel türü vardır:

\begin{itemize}
    \item \textbf{Tek Yönlü ANOVA (One-Way ANOVA):} Tek bir bağımsız değişkenin (grup) birden fazla düzeyi arasındaki farkı test etmek için kullanılır. Örneğin, farklı dozaj seviyelerine sahip üç farklı ilaç grubu arasındaki etkileri karşılaştırmak için tek yönlü ANOVA kullanabilirsiniz.
    \item \textbf{İki Yönlü ANOVA (Two-Way ANOVA):} İki bağımsız değişkenin (grup ve faktör) etkilerini incelemek için kullanılır. İki yönlü ANOVA, gruplar arası ve faktörler arası etkileri ayrı ayrı ve etkileşim etkisini de değerlendirir.
\end{itemize}

\[ F = \frac{MS_{between}}{MS_{within}} \]
\[ MS_{between} = \frac{SS_{between}}{df_{between}} \]
\[ MS_{within} = \frac{SS_{within}}{df_{within}} \]
\[ df_{between} = k - 1 \]
\[ df_{within} = N - k \]

\begin{itemize}
	\item $k$: Grup sayısı.
	\item $N$: Toplam gözlem sayısı.
	\item $SS_{between}$: Grup arası toplam kareler.
	\item $SS_{within}$: Grup içi toplam kareler.
	\item $MS_{between}$: Grup arası ortalama kareler.
	\item $MS_{within}$: Grup içi ortalama kareler.
	\item $df_{between}$: Grup arası serbestlik derecesi.
	\item $df_{within}$: Grup içi serbestlik derecesi.
\end{itemize}

\subsubsection{Python Kodu}

\begin{lstlisting}[language=Python]
import numpy as np
from scipy import stats

group1 = [65, 72, 75, 68, 69]
group2 = [72, 78, 82, 74, 70]
group3 = [60, 65, 73, 68, 75]

# Tek yonlu ANOVA 
f_statistic, p_value = stats.f_oneway(group1, group2, group3)

print("F istatistigi:", f_statistic) # F istatistigi: 2.7050938337801593
print("P degeri:", p_value) # P degeri: 0.10721776783116659

alpha = 0.05
if p_value < alpha:
    print("Null hipotez reddedildi: Gruplar arasinda anlamli bir fark vardir.")
else:
    print("Null hipotez kabul edildi: Gruplar arasinda anlamli bir fark yoktur.")

# Output
# Null hipotez kabul edildi: Gruplar arasinda anlamli bir fark yoktur.
\end{lstlisting}

\subsubsection{R Kodu}

\begin{lstlisting}[language=R]
aov(df$chol ~ df$age_groups)
\end{lstlisting}

\newpage

\subsection{Mann-Whitney U Testi}
Mann-Whitney U testi, iki bağımsız örneklem grubunun medyan değerleri arasındaki istatistiksel anlamlılığı değerlendirmek için kullanılan bir non-parametrik hipotez testidir. Mann-Whitney U testi, verilerin dağılımının normalliğini karşılamadığında veya sıralı verilerle çalışıldığında kullanışlıdır. Bu test, grupların merkezi eğilimlerini karşılaştırır ve gruplar arasındaki farkı test eder. Mann-Whitney U testinin iki ana türü vardır:

\begin{itemize}
    \item \textbf{Bağımsız Mann-Whitney U Testi:} İki bağımsız örneklem grubunun medyan değerleri arasındaki farkı test etmek için kullanılır. Bu test, gruplar arasındaki medyan değerlerinin farklı olup olmadığını değerlendirir.
    \item \textbf{İçiçe Mann-Whitney U Testi:} Aynı örneklem grubunun farklı koşullar altında elde edilen verilerinin medyan değerlerini karşılaştırmak için kullanılır. Bu test, aynı grup içindeki iki koşulun medyan değerleri arasındaki farkı test eder.
\end{itemize}

\subsubsection{Python Kodu}

\begin{lstlisting}[language=Python]
import numpy as np
from scipy import stats

group1 = [25, 30, 35, 40, 45]
group2 = [30, 35, 40, 45, 50]

# Bagimsiz Mann-Whitney U Testi
U_statistic, p_value = stats.mannwhitneyu(group1, group2)

print("U istatistigi:", U_statistic) # U istatistigi: 8.0
print("P degeri:", p_value) # P degeri: 0.39761475195653073

alpha = 0.05
if p_value < alpha:
    print("Null hipotez reddedildi: Gruplar arasinda anlamli bir medyan farki vardir.")
else:
    print("Null hipotez kabul edildi: Gruplar arasinda anlamli bir medyan farki yoktur.")

# Output
# Null hipotez kabul edildi: Gruplar arasinda anlamli bir medyan farki yoktur.
\end{lstlisting}

\newpage

\subsection{Wilcoxon İşaretli Sıralar Testi}
Wilcoxon İşaretli Sıralar Testi (Wilcoxon Signed-Rank Test), bir grup içindeki iki bağımlı örneklem arasındaki medyan farkını değerlendirmek için kullanılan bir non-parametrik hipotez testidir. Bu test, gruplar arasındaki merkezi eğilimin farklı olup olmadığını belirlemek amacıyla kullanılır. Wilcoxon İşaretli Sıralar Testi, verilerin normallik varsayımını karşılayamadığında veya sıralı verilerle çalışıldığında tercih edilir. Wilcoxon İşaretli Sıralar Testi'nin iki temel türü vardır:

\begin{itemize}
    \item \textbf{İki Örneklem Wilcoxon İşaretli Sıralar Testi:} İki bağımlı grup arasındaki medyan farkını test etmek için kullanılır. Bu test, aynı gruptaki iki farklı koşul altında elde edilen verilerin medyanlarını karşılaştırır.
    \item \textbf{Bir Örneklem Wilcoxon İşaretli Sıralar Testi:} Bir grup içindeki örneklem verilerinin medyan değeri ile bir teorik medyan değerini karşılaştırmak için kullanılır. Bu test, bir grup içindeki verilerin bir teorik dağılıma uygunluğunu değerlendirir.
\end{itemize}

\subsubsection{Python Kodu}

\begin{lstlisting}[language=Python]
import numpy as np
from scipy import stats

group1 = [25, 30, 35, 40, 45]
group2 = [30, 35, 40, 45, 50]

# Iki orneklem Wilcoxon Isaretli Siralar Testi
statistic, p_value = stats.wilcoxon(group1, group2)

print("Test istatistigi:", statistic) # Test istatistigi: 0.0
print("P degeri:", p_value) # P degeri: 0.0625

alpha = 0.05
if p_value < alpha:
    print("Null hipotez reddedildi: Gruplar arasinda anlamli bir medyan farki vardir.")
else:
    print("Null hipotez kabul edildi: Gruplar arasinda anlamli bir medyan farki yoktur.")

# Output
# Null hipotez kabul edildi: Gruplar arasinda anlamli bir medyan farki yoktur.
\end{lstlisting}

\subsubsection{R Kodu}

\begin{lstlisting}[language=R]
wilcox.test(x = warpbreaks$breaks, mu = 40)
\end{lstlisting}

\newpage

\subsection{Pearsons Korelasyon Testi}
Pearson Korelasyon Testi, iki sürekli değişken arasındaki ilişkiyi değerlendirmek için kullanılan bir parametrik istatistiksel testtir. Pearson Korelasyonu, bu iki değişken arasındaki lineer ilişkiyi ölçer ve bu ilişkinin ne kadar güçlü olduğunu ifade eder. Korelasyon, iki değişkenin nasıl birlikte değiştiğini incelemek için kullanılır. Pearson korelasyonunun iki ana formülü vardır:

\begin{itemize}
    \item \textbf{Pearson Korelasyon Katsayısı (r):} Bu, iki sürekli değişken arasındaki lineer ilişkiyi ölçer. Pearson korelasyonu, -1 ile 1 arasında bir değere sahiptir. -1, tam tersi bir ilişkiyi, 1 ise mükemmel bir pozitif ilişkiyi ifade eder. 0 ise ilişki olmadığını gösterir.
    \item \textbf{Pearson Korelasyon Katsayısı İnferansı:} Korelasyon katsayısının anlamlılığını değerlendirmek için kullanılır. Bu, korelasyonun rastgele mi yoksa gerçek bir ilişkiyi yansıttığını belirlemeye yardımcı olur.
\end{itemize}

\subsubsection{Python Kodu}

\begin{lstlisting}[language=Python]
import numpy as np
from scipy import stats

x = np.array([2, 4, 6, 8, 10])
y = np.array([1, 3, 5, 7, 9])

# Pearson Korelasyon Katsayisi ve p degeri
correlation_coefficient, p_value = stats.pearsonr(x, y)

print("Pearson Korelasyon Katsayisi (r):", correlation_coefficient) # Pearson Korelasyon Katsayisi (r): 1.0
print("P degeri:", p_value) # P degeri: 0.0

alpha = 0.05
if p_value < alpha:
    print("Korelasyon anlamlidir: Iki degisken arasinda anlamli bir lineer iliski vardir.")
else:
    print("Korelasyon anlamli degildir: Iki degisken arasinda anlamli bir lineer iliski yoktur.")

# Output
# Korelasyon anlamlidir: Iki degisken arasinda anlamli bir lineer iliski vardir.
\end{lstlisting}

\subsubsection{R Kodu}

\begin{lstlisting}[language=R]
cor.test(iris$Sepal.Width , iris$Sepal.Length , method = "pearson")
cor.test(iris$Sepal.Width , iris$Sepal.Length , method = "pearson" , alternative = "less")
cor.test(iris$Sepal.Width , iris$Sepal.Length , method = "pearson" , alternative = "greater")
\end{lstlisting}

\newpage

\subsection{Shapiro-Wilk Testi}
Shapiro-Wilk testi, bir veri kümesinin normal dağılıma uyup uymadıpını test etmek için kullanılan bir normallik testidir. Parametrik testlerin ön koşulu olan normal dağılım varsayımının geçerli olup olmadığını anlamak için kullanılır. Shapiro-Wilk testi, bir veri kümesinin normal dağılıma ne kadar iyi uyduğunu değerlendirir. Veri boyutu 30'dan fazla ise Shapiro-Wilk, 30'dan az ise Kolmogorov-Smirnov testi uygulanması tavsiye edilir. p değeri 0.05'den küçükse, veri kümesinin normal dağılıma uymadığı (H1) sonucuna varılır.

\[
W = \frac{\left( \sum_{i=1}^{n} a_i x_{(i)} \right)^2}{\sum_{i=1}^{n} (x_i - \bar{x})^2}
\]

\begin{itemize}
	\item $x_(i)$: Sıralanmış veri noktaları.
	\item $\bar{x}$: Veri kümesinin ortalaması.
	\item $a_i$: Normal dağılımın ortalama ve varyansı kullanılarak hesaplanan sabitler.
\end{itemize}

\subsubsection{R Kodu}

\begin{lstlisting}[language=R]
shapiro.test(x = iris$Sepal.Length) # p-value = 0.01018, H1
shapiro.test(x = iris$Sepal.Width) # p-value = 0.1012, H0
\end{lstlisting}

\newpage

\subsection{Levene Testi}
Levene testi, gruplar arasındaki varyansların eşit olup olmadığını test eder.

\[
W = \frac{(N - k)}{(k - 1)} \cdot \frac{\sum_{i=1}^{k} N_i (Z_{i \cdot} - Z_{\cdot \cdot})^2}{\sum_{i=1}^{k} \sum_{j=1}^{N_i} (Z_{ij} - Z_{i \cdot})^2}
\]

\begin{itemize}
	\item $N$: Toplam gözlem sayısı.
	\item $k$: Grup sayısı.
	\item $N_i$: i'inci gruptaki gözlem sayısı.
	\item $Z_{ij}$: i'inci gruptaki j'inci gözlemden ortalamanın çıkarılmasıyla elde edilen değer.
	\item $Z_{i.}$: i'inci gruptaki gözlemlerin ortalaması.
	\item $Z_{..}$: Tüm gözlemlerin ortalaması.
\end{itemize}

\subsubsection{R Kodu}

\begin{lstlisting}[language=R]
# H0: Varyanslar homojendir.
# H1: Varyanslar homojen degildir.
leveneTest(df$Sepal.Width ~ as.character(df$Species))
\end{lstlisting}

\newpage

\subsection{Bartlett Testi}
Bartlett testi, varyansların normal dağıldığını varsayarak eşitliğini test eder. Verilerin normal dağıldığını varsayar ve varyansların eşitliği hipotezini reddetmek için bir test istatistiği kullanır.

\[
\chi^2 = \frac{(N - k) \ln(s_p^2) - \sum_{i=1}^{k} (N_i - 1) \ln(s_i^2)}{1 + \frac{1}{3(k-1)} \left( \sum_{i=1}^{k} \frac{1}{N_i - 1} - \frac{1}{N - k} \right)}
\]

\begin{itemize}
	\item $N$: Toplam gözlem sayısı.
	\item $k$: Grup sayısı.
	\item $N_i$: i'inci gruptaki gözlem sayısı.
	\item $s_i^2$: i'inci grubun varyansı.
	\item $s_p^2$: Ağırlıklı ortalama varyans.
\end{itemize}

\subsubsection{R Kodu}

\begin{lstlisting}[language=R]
# H0, varyanslar homojendir.
# H1, varyanslar homojen degildir.
bartlett.test(df$Sepal.Width ~ as.character(df$Species))
\end{lstlisting}

\newpage

\subsection{Brown-Forsythe Testi}
Levene testine benzerdir. Farklı olarak ortalamadan ziyade medyan kullanır. Böylece uç değerlerden daha az etkilenir.

\[
W = \frac{(N - k)}{(k - 1)} \cdot \frac{\sum_{i=1}^{k} N_i (Z_{i \cdot} - Z_{\cdot \cdot})^2}{\sum_{i=1}^{k} \sum_{j=1}^{N_i} (Z_{ij} - Z_{i \cdot})^2}
\]

\begin{itemize}
	\item $N$: Toplam gözlem sayısı.
	\item $k$: Grup sayısı.
	\item $N_i$: i'inci gruptaki gözlem sayısı.
	\item $Z_{ij}$: i'inci gruptaki j'inci medyandan mutlak sapması.
	\item $Z_{i.}$: i'inci gruptaki gözlemlerin medyanının mutlak sapmalarının ortalaması.
	\item $Z_{..}$: Tüm gruplardaki gözlemlerin medyanının mutlak sapmalarının ortalaması.
\end{itemize}

\newpage

\subsection{Fligner-Killeen Testi}
Birden fazla grubun varyanslarının eşit olup olmadığını test etmek için kullanılır. Normal dağılım varsayımı gerektirmez. 

\[
H = \frac{(N - 1) \sum_{i=1}^{k} N_i (\bar{Z}_{i \cdot} - \bar{Z}_{\cdot \cdot})^2}{\sum_{i=1}^{k} \sum_{j=1}^{N_i} (Z_{ij} - \bar{Z}_{i \cdot})^2}
\]

\begin{itemize}
	\item $N$: Toplam gözlem sayısı.
	\item $k$: Grup sayısı.
	\item $N_i$: i'inci gruptaki gözlem sayısı.
	\item $Z_{ij}$: i'inci gruptaki j'inci medyandan mutlak sapması.
	\item $Z_{i.}$: i'inci gruptaki gözlemlerin medyanının mutlak sapmalarının ortalaması.
	\item $Z_{..}$: Tüm gruplardaki gözlemlerin medyanının mutlak sapmalarının ortalaması.
\end{itemize}

\subsubsection{R Kodu}

\begin{lstlisting}[language=R]
# H0, varyanslar homojendir.
# H1, varyanslar homojen degildir.
fligner.test(warpbreaks$breaks ~ warpbreaks$wool)
\end{lstlisting}

\newpage

\subsection{Tukey's HSD (Honestly Significant Difference) Testi}
ANOVA'dan sonra yapılan ve her çift grup arasındaki farkı test eden post hoc testidir. Gruplar arasındaki farkların hangi kombinasyonlarının istatistiksel olarak anlamlı olduğunu belirler.

\[  \text{HSD} = q \times \sqrt{\frac{MS_{within}}{n}} \]

\begin{itemize}
	\item $q$: Studentized range distribution value.
	\item $MS_{within}$: Grup içi ortalama kareler.
	\item $n$: Her bir grubun örneklem sayısı.
\end{itemize}

\subsubsection{R Kodu}

\begin{lstlisting}[language=R]
TukeyHSD(anova_1)
tukey_hsd(df, chol ~ age_groups)
\end{lstlisting}

\newpage

\subsection{Bonferroni Testi}
Birden fazla karşılaştırma yapıldığında toplam hata oranını kontrol etmek için kullanılan bir post hoc testidir. Her bir karşılaştırmanın anlamlılık düzeyini azaltarak toplam hata oranını kontrol eder.

\[ \alpha_{adj} = \frac{\alpha}{m} \]

\begin{itemize}
	\item $\alpha_{adj}$: Düzeltilmiş anlamlılık düzeyi.
	\item $\alpha$: Orijinal anlamlılık düzeyi.
	\item $m$: Yapılan karşılaştırma sayısı.
\end{itemize}

\newpage

\subsection{Scheffe Testi}
Gruplar arasındaki farkları belirlemek için kullanılan konservatif bir post hoc testidir. 

\[ F_{Scheffe} = (k - 1) \times F \]

\begin{itemize}
	\item $F_{Scheffe}$: Scheffe testi için F değeri.
	\item $k$: Grup sayısı.
	\item $F$: ANOVA F değeri.
\end{itemize}

\newpage

\subsection{Dunn's Test}
Dunn's testi, bağımsız gruplar arasındaki medyan farklılıklarını karşılaştırmak için kullanılan bir post hoc testidir. Kruskal-Wallis testi gibi non-parametrik testlerin ardından kullanılır.

\[ Z = \frac{R_j - R_i}{\sqrt{\frac{N(N+1)}{12} \left(\frac{1}{n_j} + \frac{1}{n_i}\right)}} \]

\begin{itemize}
	\item $Z$: Z skoru.
	\item $R_j$ ve $R_i$: Grupların sıra ortalamaları.
	\item $N$: Toplam gözlem sayısı.
	\item $n_j$ ve $n_i$: İlgili grupların gözlem sayıları.
\end{itemize}

\newpage

\subsection{Kruskal-Wallis Testi}
Bağımsız örneklem gruplarının medyanları arasında fark olup olmadığını belirlemek için kullanılan non-parametrik bir testtir. Bu test ANOVA'nın parametrik olmadığı durumlarda (yani verilerin normal dağılım göstermediği veya varyansların homojen olmadığı durumlarda) kullanılır.

\[ H = \left( \frac{12}{N(N+1)} \sum_{i=1}^{k} \frac{R_i^2}{n_i} \right) - 3(N+1) \]

\begin{itemize}
	\item $N$: Tüm gruplardaki toplam gözlem sayısı.
	\item $k$: Grup sayısı.
	\item $R_i$: i'inci grubun sıra toplamı.
	\item $n_i$: i'inci gruptaki gözlem sayısı.
\end{itemize}

\newpage

\subsection{Kolmogorov-Smirnov Testi}
Bir örneklem grubunun belirli bir dağılıma uyup uymadığını veya iki örneklem grubunun aynı dağılımdan gelip gelmediğini test etmek için kullanılan non-parametrik bir testtir. Dağılımların şekillerini karşılaştırır.

\begin{itemize}
	\item \textbf{Tek Örneklem Durumu}: Bir örneklem grubunun belirli bir teorik dağılıma uyup uymadığını test etmek.
	\item \textbf{İki Örneklem Durumu}: İki bağımsız örneklem grubunun aynı dağılımdan gelip gelmediğini test etmek.
\end{itemize}

Tek örneklem için;

\[ D = \sup_x | F_n(x) - F(x) | \]

\begin{itemize}
	\item $\sup_x$: Tüm x değerleri üzerindeki en büyük farkı temsil eder.
	\item $F_n(x)$: Örneklem kümülatif dağılım fonksiyonu.
	\item $F(x)$: Teorik kümülatif dağılım fonksiyonu.
\end{itemize}

İki örneklem için;

\[ D = \sup_x | F_{1,n}(x) - F_{2,m}(x) | \]

\begin{itemize}
	\item $F_{1,n}$: İlk örneklemin empirik kümülatif dağılım fonksiyonu.
	\item $F_{2,m}$: İkinci örneklemin empirik kümülatif dağılım fonksiyonu.
\end{itemize}

\newpage

\subsection{MANOVA (Multivariate Analysis of Variance)}
Birden fazla bağımlı değişkenin bir veya daha fazla bağımsız değişken tarafından aynı anda etkilenip etkilenmediğini belirtmek için kullanılır. MANOVA, ANOVA'nın geliştirilmiş bir versiyonudur ve bağımlı değişkenler arasındaki korelasyonları da dikkate alır. MANOVA testi, bağımlı değişkenlerin ortak varyansını analiz ederek, gruplar arasındaki çoklu değişken kombinasyonları açısından fark olup olmadığını belirler. MANOVA, genellikle Wilks Lambda istatistiği kullanılarak değerlendirilir. Wilks Lambda istatistiği modelin genel uyumunu değerlendirir ve küçük değerler bağımsız değişkenlerin bağımlı değişkenler üzerinde önemli bir etkiye sahip olduğunu gösterir.

\[ \Lambda = \frac{\det(E)}{\det(H + E)} \]

\begin{itemize}
	\item $E$: Hata matrisi (error matrix).
	\item $H$: Hipotez matrisi.
	\item $\det$: Determinant imleci.
\end{itemize}

\subsubsection{R Kodu}

\begin{lstlisting}[language=R]
manova(cbind(chol , thalch) ~ cp , data = heart )
Manova(model2 , test.statistic = "Pillai")
\end{lstlisting}

\subsubsection{Wilks Lambda İstatistiği}

\[ V = -\left( N - \frac{1}{2}(p + k + 1) \right) \ln(\Lambda) \]

\begin{itemize}
	\item $N$: Gözlem sayısı.
	\item $p$: Bağımlı değişken sayısı.
	\item $k$: Grupların sayısı.
\end{itemize}


\newpage

\subsection{Hotelling's $T^2$ Testi}
MANOVA sonrası her bir bağımlı değişken için bağımsız değişken düzeylerinin farklarını belirlemek amacıyla kullanılan bir testtir.

\[ T^2 = n (\bar{X}_1 - \bar{X}_2)' S^{-1} (\bar{X}_1 - \bar{X}_2) \]

\begin{itemize}
	\item $\bar(X)_1$ ve $\bar(X)_2$: İki grup ortalaması.
	\item $S$: Pooled covariance matrix.
	\item $n$: Örneklem büyüklüğü.
\end{itemize}

\newpage

\subsection{Binom Testi}
Binom testi, belirli bir başarı oranına sahip olup olmadığını test etmek için kullanılan non-parametrik bir testtir. Tek bir örneklemden elde edilen başarı sayısını, belirli bir teorik başarı oranı ile karşılaştırarak hipotez testi yapar. Verilerin ikili (binary) durumda olması gerekir. Başarıların Bernoulli dağılımına sahip olduğunu varsayar.

\[ P(X = k) = \binom{n}{k} p^k (1 - p)^{n - k} \]

\begin{itemize}
	\item $n$: Toplam deneme sayısı.
	\item $k$: Gözlenen başarı sayısı.
	\item $p$: Teorik başarı sayısı.
	\item $\binom{n}{k}$: Binom katsayısı.
\end{itemize}

\subsubsection{R Kodu}

\begin{lstlisting}[language=R]
# H0: X orani 0.5'e esittir.
# H1: X orani 0.5'e esit degildir.
binom.test(x = 35 , n = 50, p = 0.5)

# H0: X orani 0.5'e esittir ve kucuktur.
# H1: X orani 0.5'ten buyuktur.
binom.test(x = 35 , n = 50, p = 0.5, alternative='greater')
\end{lstlisting}

\newpage

\subsection{Fisher's Exact Testi}
İki kategorik değişkenin bağımsız olup olmadığını test etmek için kullanılan non-parametrik bir testtir. Küçük örneklemlerde kullanılır. 2x2 kontingensi tablosu için uygulanır ve iki nominal değişken arasındaki ilişkiyi değerlendirir.

\[ p = \frac{(a+b)!(c+d)!(a+c)!(b+d)!}{n!a!b!c!d!} \]

\begin{itemize}
	\item $a,b,c,d$: 2x2 kontingensi tablosundaki gözlenen frekanslar.
	\item $n$: Toplam gözlem sayısı $n = a + b + c + d$
\end{itemize}

\subsubsection{R Kodu}

\begin{lstlisting}[language=R]
# 2 x 2 odds ratio
fisher.test(table(df))
fisher.test(table(df) , alternative = 'less')
fisher.test(table(df) , alternative = 'greater')
\end{lstlisting}

\newpage

\subsection{McNemar Testi}
Bir grup içindeki eşleştirilmiş (bağımlı) verilerin karşılaştırılması için kullanılan non-parametrik bir testtir. 2x2 kontingensi tablosu oluşturulur ve bu tablodaki hücre frekansları karşılaştırılarak hipotez testi yapılır. Eşleştirilmiş iki grup arasında değişiklik olup olmadığını belirlemek için kullanılır.

\[ \chi^2 = \frac{(b - c)^2}{b + c} \]

\begin{itemize}
	\item $b$: Hem ilk durumda $X = 1$ ve ikinci durumda $Y = 0$ olanların sayısı.
	\item $c$: Hem ilk durumda $X = 0$ ve ikinci durumda $Y = 1$ olanların sayısı.
\end{itemize}

\subsubsection{R Kodu}

\begin{lstlisting}[language=R]
mcnemar.test(df)
\end{lstlisting}

\newpage

\subsection{Kendall Rank Korelasyon Testi}
İki değişken arasındaki ilişkiyi değerlendirmek için kullanılan non-parametrik bir testtir. Sıralı verilerin ilişkisini incelemek için kullanılır. Verilerin normal dağılım göstermediği durumlarda terchil edilir. -1 ile 1 arasında bir değer alır. $\tau_b = 1$ ise tamamen pozitif bir sıralama ilişkisi, $\tau_b = -1$ ise tamamen negatif bir sıralama ilişkisi, $\tau_b = 0$ ise ilişki yok demektir.

\[ \tau_b = \frac{n_c - n_d}{\sqrt{(n_0 - n_1)(n_0 - n_2)}} \]

\begin{itemize}
	\item $n_c$: Concordant çiftlerin sayısı.
	\item $n_d$: Discordant çiftlerin sayısı.
	\item $n_0$: Toplam çift sayısı.
	\item $n_1$: İlk değişkenin tüm çiftlerdeki sıralı çiftlerin sayısı.
	\item $n_2$: İkinci değişkenin tüm çiftlerdeki sıralı çiftlerin sayısı.
\end{itemize}

\newpage