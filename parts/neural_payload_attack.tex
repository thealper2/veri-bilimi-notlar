\section{Neural Payload Attack}

Neural payload saldırısı, bir yapay zeka modelinin davranışını gizlice değiştirmek amacıyla model dosyalarına kasıtlı olarak eklenen zararlı bir kod parçasıdır.

\begin{itemize}
    \item \textbf{Model Poisoning}: Eğitim verisine kötü niyetli örnekler ekleyerek modeli yanıltabilirler.
    \item \textbf{Adversarial Attack}: Giriş verisine küçük değişiklikler yaparak modelin yanlış sonuç üretmesini sağlayabilirler.
    \item \textbf{Backdoor}: Modelin belirli bir girdiye özel bir çıktı üretmesini sağlayacak şekilde manipüle edebilirler.
\end{itemize}


\newpage